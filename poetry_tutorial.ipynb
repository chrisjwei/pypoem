{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing Crowdsourced Poetry Using NLTK\n",
    "\n",
    "Poetry is the art of putting words together to form thoughtful and provoking imagery. In the modern age, nobody has time for creative thought anymore -- so lets use technology to create poetry for us.\n",
    "\n",
    "This tutorial will consist of three parts  \n",
    "\n",
    "1. Prerequisites: We will walk through how to install the CMUDICT corpus from NLTK and go through some examples to familarize you with how to use the dictionary.\n",
    "2. Poetry Library: We will build from scratch a poetry library that will interface a database to computationally build poetry base on rhyming schemes and syllable counts.\n",
    "3. Application of Library: We will build a quick example to generate poetry from the subtitle files from a bunch of Marvel films"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "#### NLTK\n",
    "\n",
    "We will be using NLTK, a python natural language processing tool kit. Specifically, we will be using one of NLTK's many\n",
    "corpuses: CMU Pronunciation dictionary, a giant python-like dictionary that provides pronunciations of over 100,000 words developed here at CMU!\n",
    "\n",
    "First, we will need to install the nltk python library, which you should already have if you have anaconda. From here, we will also need to download the CMU Dictionary corpus, which does not come preinstalled with NLTK. The NLTK downloader can be run through any python command line and will appear as a GUI for some operating systems, or some text-based GUI for others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk, sqlite3, re, random\n",
    "try:\n",
    "    from nltk.corpus import cmudict\n",
    "except:\n",
    "    nltk.download(\"cmudict\")\n",
    "    from nltk.corpus import cmudict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can create a python dictionary and we can index into it with any particular word. We can see that typical english words including proper nouns exist in our dictionary, but capitalized words do not.\n",
    "\n",
    "Our pronunciation dictionary maps words to an array of different possible pronunciations of the key word, where each pronunciation is an array of phonemes\n",
    "represented by alphabetical characters and optionally a number from 0-2 to denote primary, secondary, or no stress for vowels. You can find more information about phonemes here: http://www.speech.cs.cmu.edu/cgi-bin/cmudict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'hello': [[u'HH', u'AH0', u'L', u'OW1'], [u'HH', u'EH0', u'L', u'OW1']]\n",
      "'world': [[u'W', u'ER1', u'L', u'D']]\n",
      "'chris': [[u'K', u'R', u'IH1', u'S']]\n",
      "'aint' does not exist\n",
      "'ain't': [[u'EY1', u'N', u'T']]\n",
      "'pittsburgh': [[u'P', u'IH1', u'T', u'S', u'B', u'ER0', u'G']]\n",
      "'Chris' does not exist\n",
      "'Hello' does not exist\n",
      "'0' does not exist\n"
     ]
    }
   ],
   "source": [
    "d = cmudict.dict()\n",
    "words = [\"hello\", \"world\", \"chris\", \"aint\", \"ain't\", \"pittsburgh\", \"Chris\", \"Hello\", \"0\"]\n",
    "for word in words:\n",
    "    try:\n",
    "        print \"'\" + word + \"': \" + str(d[word])\n",
    "    except KeyError:\n",
    "        print \"'\" + word + \"'\" + \" does not exist\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sqlite3\n",
    "Typically, we would want to load data into memory so we have more freedom in manipulating it. However, in our case, for us quality will be achieved by quantity. With more data points we will get poems with more variety. Therefore, it is important to offload data because we cannot reasonably load large amounts of data to memory and expect to be able to parse it through it efficiently (especially in python \\*rolls eyes\\*). So in order to efficiently parse through our data, we need to take advantage of the many years of SQL optimizations and effectively transform our problem into a bunch of SQL queries.\n",
    "\n",
    "In this library, we will be using SQLite3 due to its ease of entry. We can create databases represented as files, access those databases, insert, update, select etc. Here is a quick example of how to use the python sqlite3 library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'Chris', u'Wei')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"tutorial.db\")\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"CREATE TABLE users (id INTEGER PRIMARY KEY, firstName TEXT, lastName TEXT)\")\n",
    "cursor.execute('INSERT INTO users (firstName, lastName) VALUES (?,?)',[\"Chris\",\"Wei\"])\n",
    "cursor.execute(\"SELECT * FROM users\")\n",
    "results = cursor.fetchall()\n",
    "cursor.execute(\"DROP TABLE users\")\n",
    "conn.commit()\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poetry library\n",
    "\n",
    "With NLTK's CMU Dictionary, we have all that we need to create a pretty decent poetry library that will let us create interesting poetry. Let us define a class called Line, which will represent a single line of text, Poem, that will represent a poem (a collection of lines), and a class called PoemFactory that will load/store the lines in a database, and create Poem instances given its resources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line\n",
    "\n",
    "Lets define the basis of our poems, the Line class. We will initialize an instance of Line by providing it some raw content that we will, for now, provide through an array of strings. The raw content will be parsed and verified through the static method verify_and_parse(), providing some diagnostic which will tell us what went wrong for each invalid line. If all is well, our verify_and_parse function will return a list of pronunciations for each word that it found in the input content.\n",
    "\n",
    "From here, we need to collect two more pieces of information: the total syllable count, and the rhyme of that particular line. \n",
    "\n",
    "For syllable count, we simply count the number of phonemes that end with a numeric character.\n",
    "\n",
    "For our rhyme, we need to generate a unique key that classifies the line into a particular rhyme catagory. If our key is too generic, we will get more matches but lower quality rhymes; if our key is too specific we won't get enough matches to make a poem.\n",
    "\n",
    "For this implementation, we will be taking the last vowel and all proceding phonemes and concatenating them as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Line(object):\n",
    "    '''\n",
    "        content: string - The source content for this line\n",
    "        is_valid: bool - Whether this line is valid\n",
    "        words: List<string> - The words found in the content\n",
    "        parsed: List<List<string>> - The parsed pronuncation of this line\n",
    "        diagnostics: string - Why the line failed to parse (\"Success\" otherwise)\n",
    "    '''\n",
    "    \n",
    "    regex = re.compile(\"[a-z]+(?:'[a-z]+)?\")\n",
    "    pdict = cmudict.dict()\n",
    "    \n",
    "    @staticmethod\n",
    "    def verify_and_parse(content):\n",
    "        '''\n",
    "            Given a string, finds all the words in the string and verifies each word has a pronunciation in CMUDICT\n",
    "            args:\n",
    "                content: string\n",
    "            returns:\n",
    "                (is_valid: bool, words: List<string>, pronunciations: List<List<string>>, status: string) \n",
    "        '''\n",
    "        # find all words in content\n",
    "        words = Line.regex.findall(content.lower())\n",
    "        if (len(words) == 0):\n",
    "            return (False, [], None, \"No words found\")\n",
    "        for word in words:\n",
    "            if not(word in Line.pdict):\n",
    "                return (False, words, None, \"No pronunciation found for word '\" + word + \"'\")\n",
    "        return (True, words, [Line.pdict[word][0] for word in words], \"Valid\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_rhyme_phoneme(pron):\n",
    "        '''\n",
    "            Given a pronuncation, returns a unique key that maps to all pronunciations that rhyme with the given\n",
    "            pronuncation.\n",
    "            args:\n",
    "                pron: List<string>\n",
    "            returns:\n",
    "                key: string\n",
    "        '''\n",
    "        # find all the vowels and their indices\n",
    "        vowels = [(i,vow) for (i,vow) in enumerate(pron) if vow[-1].isnumeric()]\n",
    "        # if no vowels present, take the whole pronuncation\n",
    "        if (len(vowels) == 0):\n",
    "            return reduce(lambda x,y: x+y, pron)\n",
    "        # take the last vowel and return the concatenation of the vowel\n",
    "        # and all phonemes occuring after it seperated by spaces\n",
    "        # removing the stress indicator on the vowel\n",
    "        (i,_) = max(vowels, key=lambda x: x[0])\n",
    "        return reduce(lambda x,y: x + \" \" + y, [pron[i][:-1]] + pron[i+1:])\n",
    "        \n",
    "    \n",
    "    def __init__(self, content):\n",
    "        self.content = content.strip().replace('\\n', ' ')\n",
    "        (self.is_valid, self.words, self.parsed, self.diagnostics) = Line.verify_and_parse(self.content)\n",
    "        if (self.is_valid):\n",
    "            self.syllable_count = sum([len([syl for syl in pron if syl[-1].isnumeric()]) for pron in self.parsed])\n",
    "            last_pron = self.parsed[-1]\n",
    "            self.rhyme = Line.extract_rhyme_phoneme(last_pron)\n",
    "    \n",
    "    def to_sql_params(self):\n",
    "        return (self.content, self.syllable_count, self.rhyme,)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A) init function\n",
    "To create a line, we must first pass it a variable `content` which is the raw string contents of that particular line. In this implementation, we first strip all `\\n` characters so that we don't get any unsightly newlines in our poems. We then call `verify_and_parse` which will tell us if this line can be parsed in a meaningful way given our implementation. The return value of `verify_and_parse = (is_valid, parsed, diagnostics)` which tells us whether the Line is a valid line, the pronunciation of the line given as an array of array of phonemes (we arbitrarily take the first pronunciation from the dictionary), and the reason why the Line failed to be created.\n",
    "\n",
    "Provided all went well in parsing the line, we need to count the number of syllables in our line. This is done by going through each of the phonemes and counting the number of phonemes that end with a integer, indicating a stress vowel.\n",
    "\n",
    "`cmud[\"misdemeanor\"] = [u'M', u'IH2', u'S', u'D', u'AH0', u'M', u'IY1', u'N', u'ER0', u'Z']\n",
    "vowels = [u'IH2', u'AH0', u'IY1', u'ER0']\n",
    "num_syllables = 4\n",
    "`\n",
    "\n",
    "Next, we need to extract some sort of rhyming information from the last word. We will go into more depth later on about this.\n",
    "\n",
    "#### B) verify_and_parse\n",
    "For each input, we should verify that each word in the input is a valid word (has an entry in our dictionary) and should then parse each word by converting each word into an arbitrary pronunciation of said word (this implementation simply chooses the first pronunciation)\n",
    "\n",
    "#### C) extract_rhyme_phoneme\n",
    "Given a pronunciation, this function will return a string that represents groupings a particular word. For example, [\"word\", \"curd\", \"bird\"] all belong in the same grouping since the last vowel to occur to the end of the word is \"ER D\". We will use this function to group rows in our sql table together when searching for rhymes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poem\n",
    "\n",
    "Now, we can create a simple Poem class that represents a poem, which intuitively is an ordered collection of Line instances, along with some metadata like author or title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Poem(object):\n",
    "    \n",
    "    def __init__(self, lines, title, author):\n",
    "        '''\n",
    "            Creates a new poem\n",
    "            args:\n",
    "                lines: list<Line>\n",
    "                title: string\n",
    "                author: string\n",
    "        '''\n",
    "        self.title = title\n",
    "        self.lines = lines\n",
    "        self.author = author\n",
    "    \n",
    "    def __str__(self):\n",
    "        '''\n",
    "            Override default string converter\n",
    "        '''\n",
    "        line_string = reduce(lambda x,y: x + y, map(lambda line: line.content + \"\\n\", self.lines))\n",
    "        author_string = \"-- \" + self.author\n",
    "        title_string = self.title + '\\n'\n",
    "        sep_string = len(self.title)*\"_\" + '\\n\\n'\n",
    "        return title_string + sep_string + line_string + sep_string + author_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PoemFactory and populating our database\n",
    "\n",
    "Now, lets create a PoemFactory that will create poems for us. All we need to do is feed the PoemFactory resources and tell it to spit out new poems for us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ResourceError(Exception):\n",
    "    pass\n",
    "\n",
    "class PoemFactory(object):\n",
    "    def __init__(self, database_path, new=False):\n",
    "        '''\n",
    "            Initializes a new PoemFactory\n",
    "            args:\n",
    "                database_path: string\n",
    "                new: bool\n",
    "        '''\n",
    "        self.conn = sqlite3.connect(database_path)\n",
    "        if (new):\n",
    "            self.reset_database()\n",
    "        \n",
    "    def reset_database(self):\n",
    "        '''\n",
    "            Resets the current database\n",
    "        '''\n",
    "        c = self.conn.cursor()\n",
    "        c.execute('''DROP TABLE IF EXISTS line;''')\n",
    "        c.execute('''CREATE TABLE line (id INTEGER PRIMARY KEY,\n",
    "                                        raw_text TEXT NOT NULL,\n",
    "                                        syllable_count INTEGER NOT NULL,\n",
    "                                        rhyme TEXT);''')\n",
    "        self.conn.commit()\n",
    "    \n",
    "    def insert_many(self, resources):\n",
    "        '''\n",
    "            Updates the current database with new resources\n",
    "            args:\n",
    "                resources: list<string>\n",
    "            returns:\n",
    "                num_failed: int\n",
    "        '''\n",
    "        n = 0\n",
    "        new_lines = []\n",
    "        unsuccessful_lines= []\n",
    "        for resource in resources:\n",
    "            line = Line(resource)\n",
    "            if not(line.is_valid):\n",
    "                unsuccessful_lines.append(line)\n",
    "            else:\n",
    "                new_lines.append(line)\n",
    "        # insert many into our database\n",
    "        c = self.conn.cursor()\n",
    "        c.executemany('''INSERT INTO line (raw_text, syllable_count, rhyme) VALUES (?,?,?)''',\n",
    "                      [line.to_sql_params() for line in new_lines])\n",
    "        self.conn.commit()\n",
    "        return unsuccessful_lines\n",
    "    \n",
    "    def new_poem(self, pattern, syllable_ranges, title=\"Untitled\", author=\"Anonymous\"):\n",
    "        '''\n",
    "            Creates a new poem using the current database following certain constraints\n",
    "            args:\n",
    "                pattern: string\n",
    "                syllable_ranges: dict<string,list<int>>\n",
    "            returns:\n",
    "                poem: Poem\n",
    "        '''\n",
    "        # Check for invalid inputs\n",
    "        if (len(pattern) == 0):\n",
    "            raise ValueError(\"Empty pattern\")\n",
    "            \n",
    "        # Check for valid syllable ranges\n",
    "        pattern_domain = set(pattern)\n",
    "        for p in pattern_domain:\n",
    "            if not(p in syllable_ranges):\n",
    "                raise ValueError(\"Pattern \" + p + \" does not exist in syllable_ranges\")\n",
    "            if len(syllable_ranges[p]) == 0:\n",
    "                raise ValueError(\"Empty syllable_ranges entry for \" + p)\n",
    "        \n",
    "        # Count the number of lines per pattern category\n",
    "        pattern_counts = dict.fromkeys(pattern_domain, 0)\n",
    "        for p in pattern:\n",
    "            pattern_counts[p] += 1\n",
    "        \n",
    "        # Attempt to find lines for each pattern category\n",
    "        c = self.conn.cursor()\n",
    "        \n",
    "        # Assign possible resources for each pattern group\n",
    "        possible_resources = {}\n",
    "        for p in pattern_domain:\n",
    "            requested_count = pattern_counts[p]\n",
    "            requested_syllable_range = syllable_ranges[p]\n",
    "            # group \n",
    "            c.execute('''\n",
    "                SELECT rhyme FROM\n",
    "                    (SELECT l.rhyme, count(id) as num_resources\n",
    "                     FROM line l\n",
    "                     WHERE l.syllable_count in (%s)\n",
    "                     GROUP BY l.rhyme)\n",
    "                WHERE num_resources >= (?)\n",
    "                ''' % ','.join('?'*len(requested_syllable_range)),\n",
    "                      list(requested_syllable_range) + [requested_count])\n",
    "            results = c.fetchall() # results: list[(string)]\n",
    "            if not(results):\n",
    "                raise ResourceError(p)\n",
    "            possible_resources[p] = [result[0] for result in results]\n",
    "\n",
    "        # Now that each pattern group has a set of resources that can fill its requirements\n",
    "        # we need to assign each resource to each pattern. If we want to eliminate collisions\n",
    "        # we will have to do some smart assigning here, but since this is just a tutorial\n",
    "        # and I'm lazy AF lets just assume our db is large enough that collisions are very unlikely\n",
    "        assigned_resources = {}\n",
    "        for p in pattern_domain:\n",
    "            # we will introduce randomness here so we don't get same poem over and over again\n",
    "            resource_group = random.choice(possible_resources[p])\n",
    "            requested_count = pattern_counts[p]\n",
    "            requested_syllable_range = syllable_ranges[p]\n",
    "            c.execute('''\n",
    "                SELECT raw_text\n",
    "                FROM line l\n",
    "                WHERE l.syllable_count in (%s) AND l.rhyme = (?)\n",
    "                ORDER BY RANDOM()\n",
    "                LIMIT (?)\n",
    "            ''' % ','.join('?'*len(requested_syllable_range)),\n",
    "                      list(requested_syllable_range) + [resource_group, requested_count])\n",
    "            assigned_resources[p] = [line[0] for line in c.fetchall()]\n",
    "        \n",
    "        lines = []\n",
    "        for p in pattern:\n",
    "            lines.append(Line(assigned_resources[p].pop()))\n",
    "        \n",
    "        return Poem(lines, title, author)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing PoemFactory and populating with resources\n",
    "#### A) init function & reset_database\n",
    "Our init function simply creates or selects an existing database to store our instances of the Line class in. If the new flag is raised, we create a new database and call `reset_database` which essentially recreates the line table.\n",
    "#### B) insert_many\n",
    "This function simply takes in a list of strings that represent the raw data we want to convert into lines. For each line of raw data, we attempt to create an instance of Line to represent our raw data, and for each successful instance of Line created, we insert a SQL representation into our database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No pronunciation found for word 'borgleborgleborgle'\n",
      "No words found\n"
     ]
    }
   ],
   "source": [
    "factory = PoemFactory(\"foo.db\", True)\n",
    "resources = [\"Borgleborgleborgle!!!\",\n",
    "             \"I drank Moet with Medusa, gave her shotguns in hell.\",\n",
    "             \"  hello world\",\n",
    "             \"From the split that I lift and inhale, it ain't hard to tell.\",\n",
    "             \"<><>< !!!> <! hello !!!!!goodbye\",\n",
    "             \"<<<<>>><<><>><{}{}{}{}\"]\n",
    "unsuccessful = factory.insert_many(resources)\n",
    "for line in unsuccessful:\n",
    "    print line.diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, u'I drank Moet with Medusa, gave her shotguns in hell.', 14, u'EH L'),\n",
       " (2, u'hello world', 3, u'ER L D'),\n",
       " (3,\n",
       "  u\"From the split that I lift and inhale, it ain't hard to tell.\",\n",
       "  14,\n",
       "  u'EH L'),\n",
       " (4, u'<><>< !!!> <! hello !!!!!goodbye', 4, u'AY')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = factory.conn.cursor()\n",
    "c.execute(\"SELECT * FROM line LIMIT 20\")\n",
    "c.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a poem\n",
    "\n",
    "Now that we have populated our database with a couple dummy lines, we can try to create a poem.\n",
    "#### C) new_poem\n",
    "This part might be a bit confusing and rightly so since most of the logic is caked into this function. Up until this point, we have created classes to represent poem lines and poems and we've gone through and created a method of storing and accessing these lines. We have also done a little bit of analysis by extracting out rhyme phonemes that simplifies the process of generating a new poem.\n",
    "\n",
    "First we need to understand the two inputs `pattern` and `syllable_ranges`. `pattern` is a string that represents the rhyme structure of our poem. For example, `\"AABBAA\"` corresponds to a poem with six lines, where line 1,2,5,6 rhyme and 3,4 rhyme. `syllable_ranges` provides a range of desired syllable counts for each rhyme group. Continuing our example, `syllable_ranges={\"A\":range(5,10),\"B\":[6,8]}` declares that every entry into group `\"A\"` must have 5-9 syllables and every entry into `\"B\"` must have either 6 or 8 syllables. This design is obviously fairly generalized and is slightly limited, you can redesign this function if you need line by line syllable granularity.\n",
    "\n",
    "After calling `new_poem`, the input `pattern` and `syllable_ranges` are checked for consistency. We the count the number of lines we need per pattern domain. We now have two dictionaries that tell us for each pattern group the `requested_count` and `requested_syllable_range`.\n",
    "\n",
    "Now, for each pattern group we query into our database to populate a mapping between each pattern group to a pool of resource groups. We do this by filtering out all lines that do not fall in the `requested_syllable_range` and then grouping the remaining lines by its rhyme column, so all words that rhyme with eachother are grouped together. We then filter out all the groups that do not have a count that satisfies `requested_count`; all the remaining groups are valid candidates for this particular pattern group and we simply select out the rhyme column and save it for later use. If a pattern group's resources cannot be fulfilled, a `ResourceError` will be raised, which the user of our library can handle themselves.\n",
    "\n",
    "From here, we randomly select a rhyme group for each pattern group, and for each line within a pattern group, we randomly select a unique line from the assigned rhyme group. We then populate a Poem instance with the selected lines and we have ourselves a poem!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled\n",
      "________\n",
      "\n",
      "I drank Moet with Medusa, gave her shotguns in hell.\n",
      "From the split that I lift and inhale, it ain't hard to tell.\n",
      "________\n",
      "\n",
      "-- Anonymous\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    poem = factory.new_poem(pattern=\"AA\", syllable_ranges={\"A\": xrange(13,15)})\n",
    "    print poem\n",
    "except ValueError as e:\n",
    "    print \"Error: \" + str(e)\n",
    "except ResourceError as e:\n",
    "    print \"Not enough resources: \" + str(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using our poetry library\n",
    "\n",
    "Now that we have established our poetry library, we can now use our PoemFactory to save text from various sources and generate poetry! But first, lets look at some common poem structures and see how we can express them as a call to PoemFactory.new_poem().\n",
    "\n",
    "#### Triplet \n",
    "`PoemFactory.new_poem(\"AAA\", {\"A\":[7,8,9]})`  \n",
    "*Shall we go dance the hay, the hay?  \n",
    "Never pipe could ever play  \n",
    "Better shepherdâ€™s roundelay.*\n",
    "#### Limmerick\n",
    "`PoemFactory.new_poem(\"AABBA\", {\"A\":[7,8], \"B\":[7,8]})`  \n",
    "*There was an Old Man with a beard  \n",
    "Who said, 'It is just as I feared!  \n",
    "Two Owls and a Hen,  \n",
    "Four Larks and a Wren,  \n",
    "Have all built their nests in my beard!'*\n",
    "#### Haiku\n",
    "`PoemFactory.new_poem(\"ABC\", {\"A\":[5], \"B\":[7], \"C\":[5]})`  \n",
    "*Light of the moon  \n",
    "Moves west, flowers' shadows  \n",
    "Creep eastward.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Limmericks from Marvel Movies\n",
    "\n",
    "As an example, we will be using the scripts from all Marvel Movies as our datasource, and we will use our poem library to automatically generate limmericks.\n",
    "\n",
    "This example requires `pysrt` which can be easily installed through `pip install pysrt` as we will be using .SRT subtitle files which will naturally split the scripts from the movies into reasonable chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pysrt, glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2708/37935 failed to parse\n"
     ]
    }
   ],
   "source": [
    "marvel_poem_factory = PoemFactory(\"marvel.db\", True)\n",
    "# load all the srt files\n",
    "lines = []\n",
    "for filename in glob.glob('marvel_subtitles/*.srt'):\n",
    "    subs = pysrt.open(filename, encoding='iso-8859-1')\n",
    "    lines += [sub.text for sub in subs]\n",
    "unsuccessful = marvel_poem_factory.insert_many(lines)\n",
    "print str(len(unsuccessful)) + \"/\" + str(len(lines)) + \" failed to parse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since rhyming a word with itself is a lame excuse for a poem, we will do a simple cute hack to increase the number of nice poems we have checking for repeated words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def good_poem(factory, pattern, syllables, title, author, retry=5):\n",
    "    poem = None\n",
    "    for i in xrange(retry):\n",
    "        poem = factory.new_poem(pattern, syllables, title, author)\n",
    "        last_words = [line.words[-1] for line in poem.lines]\n",
    "        if len(last_words) == len(set(last_words)):\n",
    "            return poem\n",
    "    return poem "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Marvel Limmerick\n",
      "__________________\n",
      "\n",
      "Should've brought my roller blades.\n",
      "He wants flowers, he wants parades.\n",
      "- Hubble. - Hubble Telescope.\n",
      "- You don't give up, do you? - Nope!\n",
      "Keep moving! Grab those grenades!\n",
      "__________________\n",
      "\n",
      "-- Chris\n"
     ]
    }
   ],
   "source": [
    "print good_poem(marvel_poem_factory, \"AABBA\", {\"A\":[7,8], \"B\":[7,8]}, \"A Marvel Limmerick\", \"Chris\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "Something that you can see happening is that a lot of times you'll get the same word rhyming to the same word, which in my honest opinion is just bad poetry. Some improvements we can make to this library is upgrading the resource management so we don't see the same word over and over again. The rhyming scheme is not super accurate but works for most cases. We should also make bookkeeping easier so that you can store other metadata about each line you insert into so you can do stuff like this: https://vimeo.com/165395316 you can check out the code for this here https://github.com/chrisjwei/iacd-final which does not support poem structures, but has a much more developed rhyming algorithm and does everything in memory (SHAMELESS PLUG).\n",
    "\n",
    "Here is a really nice one that really capture the essence of marvel movies\n",
    "\n",
    "*It's just a metaphor, dude.  \n",
    "Big and green and buck-ass nude.  \n",
    "It's very hard to get hold of.  \n",
    "Even from the people they love.  \n",
    "I thought you'd be in a good mood.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
